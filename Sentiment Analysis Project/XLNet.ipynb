{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"XLNet.ipynb","provenance":[{"file_id":"16TlpcPT3Y8XOix_KnGPhFMpN2hje-FiU","timestamp":1588283135932},{"file_id":"1eJEPPsRXKVE_jfUXobXzCkUrovEbFNCw","timestamp":1587438474473},{"file_id":"1Z1cYZWb8j14Gy71SJ6iAYGrHgZzen5uz","timestamp":1587436797321},{"file_id":"1PY7pVMJ4sE2Hx0zaPgJiyuayhTwI4QPc","timestamp":1587421747426},{"file_id":"1Y0QPqveEiSQeGdPovtzVUjnVAo-LKTBh","timestamp":1587413761831}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"c8Prt8hQSWIT","colab_type":"code","colab":{}},"source":["import torch\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DknRx8mqhByd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"status":"ok","timestamp":1587951600681,"user_tz":240,"elapsed":9777,"user":{"displayName":"Elsa Mary Mathew","photoUrl":"","userId":"01761346962039641225"}},"outputId":"623fe060-8f6d-4977-b4eb-d8997367e2c1"},"source":["from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from nltk.tokenize.treebank import TreebankWordDetokenizer\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","!pip install emoji\n","import emoji"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","Collecting emoji\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=ef92222256341b63242893c1d41c712cbbf7a366853dff805c8b8942eeda6cec\n","  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-0.5.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MrGr1G3cngWt","colab_type":"code","colab":{}},"source":["#mounting drive for the OUTPUT directory\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","!ls /content/gdrive/'My Drive'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NJB0e48LSRj0","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NenBzlRsuMh1","colab_type":"code","colab":{}},"source":["#!pip install pytorch-transformers\n","import torch\n","import pandas as pd\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FI8IRc-ewhn6","colab_type":"code","colab":{}},"source":["from textblob import TextBlob\n","from sklearn.model_selection import train_test_split\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3c1dQKZznHj","colab_type":"code","colab":{}},"source":["df = pd.read_excel('/content/gdrive/My Drive/545 project/20thApril/Copy of Final_Emojis.xlsx')\n","#df = pd.read_csv('/content/gdrive/My Drive/545 project/emotions1.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ltb5FLo30aQ1","colab_type":"code","colab":{}},"source":["df.loc[df['Affect Dimension'] == 'anger','newlabel'] = 0\n","\n","df.loc[df['Affect Dimension'] == 'joy','newlabel'] = 1\n","\n","df.loc[df['Affect Dimension'] == 'sadness/fear','newlabel'] = 2\n","\n","df.loc[df['Affect Dimension'] == 'neutral','newlabel'] = 3\n","print (df['newlabel'][6034])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iVZNGnFkPidI","colab_type":"code","colab":{}},"source":["def is_emoji(s):\n","    count = 0\n","    for emoji1 in emoji.UNICODE_EMOJI:\n","        count += s.count(emoji1)\n","        if count > 1:\n","            return False\n","    return bool(count)\n","\n","def token_emoji_conversion(text):\n","    words2 = []\n","    words = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n","    words11=words.copy()\n","    idx=0\n","    i2=0\n","    n=0\n","    for i1, word in enumerate(words11):\n","      #print(word)\n","      if i2!=0 and n!=0:\n","        words.insert(idx, word1)\n","        idx+=1\n","        n=0\n","      if i2==0 and i1!=0:\n","        idx+=1\n","      i2=0\n","      m=0\n","      n=0\n","      for c in word:\n","      #c for c in str if c in emoji.UNICODE_EMOJI\n","        if is_emoji(c) == True:\n","          i2+=1\n","          if m==0:\n","            try:\n","              del(words[idx])\n","            except:\n","              print(words, idx)\n","          if n!=0:\n","            words.insert(idx, word1)\n","            idx+=1\n","            n=0\n","          word1 = emoji.demojize(c)\n","          word1 = word1.replace('_', ' ')\n","          word1 = word1.replace(':', '')\n","          word1 = nltk.word_tokenize((word1))\n","          for i in range(len(word1)):\n","            words.insert(idx, word1[i])\n","            #print(i)\n","            idx+=1\n","          m+=1\n","        else:\n","          if n==0:\n","            word1 = c\n","          else:\n","            word1=word1+c\n","          n+=1\n","    for token in words:\n","        if re.search('[a-zA-Z]', token):\n","            words2.append(token)\n","    \n","    #TreebankWordDetokenizer().detokenize(output)\n","    return TreebankWordDetokenizer().detokenize(words2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7QTnVpCKe5iR","colab_type":"code","colab":{}},"source":["df['Tweet']=df['Tweet'].apply(token_emoji_conversion)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"edcStoRyhgot","colab_type":"code","colab":{}},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXVkO10zvYD5","colab_type":"code","colab":{}},"source":["sentences  = []\n","for sentence in df['Tweet']:\n","  sentence = sentence+\"[SEP] [CLS]\"\n","  sentences.append(sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-ZLNf4xqyjL","colab_type":"code","colab":{}},"source":["sentences[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ueQbtRvGvkIg","colab_type":"code","colab":{}},"source":["!pip install transformers\n","\n","from transformers import XLNetTokenizer, XLNetForSequenceClassification, XLNetConfig\n","from sklearn.model_selection import train_test_split\n","from transformers import AdamW\n","import matplotlib.pyplot as plt\n","from keras.preprocessing.sequence import pad_sequences\n","import torch\n","from torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CAgktVTtvqD4","colab_type":"code","colab":{}},"source":["tokenizer  = XLNetTokenizer.from_pretrained('xlnet-base-cased',do_lower_case=False)\n","tokenized_text = [tokenizer.tokenize(sent) for sent in sentences]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-qVhrJ63vwmF","colab_type":"code","colab":{}},"source":["tokenized_text[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcf_Lcn8v1ZH","colab_type":"code","colab":{}},"source":["tokenizer.tokenize(\"I am GONE MAD\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GzPzcVxwwC5C","colab_type":"code","colab":{}},"source":["ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_text]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e-bqCiV0wgtX","colab_type":"code","colab":{}},"source":["print(ids[0])\n","labels = df['newlabel'].values\n","print(labels[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jXM_ycRiwo4r","colab_type":"code","colab":{}},"source":["max1 = len(ids[0])\n","for i in ids:\n","  if(len(i)>max1):\n","    max1=len(i)\n","print(max1)\n","MAX_LEN = max1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9J9oU6rpwtwy","colab_type":"code","colab":{}},"source":["input_ids2 = pad_sequences(ids,maxlen=MAX_LEN,dtype=\"long\",truncating=\"post\",padding=\"post\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bHCEw4eTxOz5","colab_type":"code","colab":{}},"source":["xtrain,xtest,ytrain,ytest = train_test_split(input_ids2,labels,test_size=0.20, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kKAzpWjrxWnV","colab_type":"code","colab":{}},"source":["print(len(input_ids2[0]))\n","print (input_ids2[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PtuoRvIHxZQu","colab_type":"code","colab":{}},"source":["Xtrain = torch.tensor(xtrain)\n","Ytrain = torch.tensor(ytrain, dtype=torch.long)\n","Xtest = torch.tensor(xtest)\n","Ytest = torch.tensor(ytest, dtype=torch.long)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JoGKQF_pxg3H","colab_type":"code","colab":{}},"source":["batch_size = 3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VaEMazvyxxVA","colab_type":"code","colab":{}},"source":["train_data = TensorDataset(Xtrain,Ytrain)\n","test_data = TensorDataset(Xtest,Ytest)\n","loader = DataLoader(train_data,batch_size=batch_size)\n","test_loader = DataLoader(test_data,batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9qq11B10Fqac","colab_type":"text"},"source":["** If the model has already been trained and checkpoint generated then uncomment the following 2 lines to load the model and skip model definition and training **"]},{"cell_type":"code","metadata":{"id":"MrAIkqKsF5sq","colab_type":"code","colab":{}},"source":["#model.load_state_dict(torch.load('/content/gdrive/My Drive/545 project/20thApril/checkpoint_xlnet_emoji/latest.ckpt'))\n","#model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9elJCRDqTJhb","colab_type":"text"},"source":["**MODEL**"]},{"cell_type":"code","metadata":{"id":"3NSpbKt6x9iF","colab_type":"code","colab":{}},"source":["config = XLNetConfig.from_pretrained('xlnet-base-cased')\n","\n","model = XLNetForSequenceClassification(config)\n","\n","model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=4)\n","model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XJenGMK3OmnU","colab_type":"code","colab":{}},"source":["device = torch.device(\"cuda\")\n","model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=4)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hCugVyTRyF4K","colab_type":"code","colab":{}},"source":["optimizer = AdamW(model.parameters(),lr=2e-5)# We pass model parameters"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tPPTBBp-yN5F","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","#criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WFfsHLF9yRBD","colab_type":"code","colab":{}},"source":["import numpy as np\n","def flat_accuracy(preds,labels): \n","    correct=0\n","    for i in range(0,len(labels)):\n","        if(preds[i]==labels[i]):\n","            correct += 1\n","    return (correct/len(labels))*100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"req_w13oyZNs","colab_type":"code","colab":{}},"source":["no_train = 0\n","epochs = 3\n","for epoch in range(epochs):\n","    model.train()\n","    loss1 = []\n","    steps = 0\n","    train_loss = []\n","    l = []\n","    for inputs,labels1 in loader :\n","        inputs.to(device)\n","        labels1.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs.to(device))\n","        loss = criterion(outputs[0],labels1.to(device)).to(device)\n","        logits = outputs[1]\n","        #ll=outp(loss)\n","        [train_loss.append(p.item()) for p in torch.argmax(outputs[0],axis=1).flatten() ]#our predicted \n","        [l.append(z.item()) for z in labels1]# real labels\n","        loss.backward()\n","        optimizer.step()\n","        loss1.append(loss.item())\n","        no_train += inputs.size(0)\n","        steps += 1\n","    print(\"Current Loss is : {} Step is : {} number of Example : {} Accuracy : {}\".format(loss.item(),epoch,no_train,flat_accuracy(train_loss,l)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IeSLY4UMGM7r","colab_type":"text"},"source":["Save the trained model."]},{"cell_type":"code","metadata":{"id":"AyZyLIkMGMGX","colab_type":"code","colab":{}},"source":["torch.save(model.state_dict(), '/content/gdrive/My Drive/545 project/20thApril/checkpoint_xlnet_emoji/latest.ckpt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EwcX4OYxGSj_","colab_type":"text"},"source":["Test() run the model on test_data and check accuracy"]},{"cell_type":"code","metadata":{"id":"Roc-o9Eqysc1","colab_type":"code","colab":{}},"source":["acc = []\n","lab = []\n","logits = []\n","t = 0\n","for inp,lab1 in test_loader:\n","  inp.to(device)\n","  lab1.to(device)\n","  t+=lab1.size(0)\n","  outp1 = model(inp.to(device))\n","  logits.append(outp1[0][1])\n","  [acc.append(p1.item()) for p1 in torch.argmax(outp1[0],axis=1).flatten() ]\n","  [lab.append(z1.item()) for z1 in lab1]\n","print(\"Total Examples : {} Accuracy {}\".format(t,flat_accuracy(acc,lab)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6rM-sRuAknp","colab_type":"code","colab":{}},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TN5MYpWzBHne","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}